{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4fc2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bc8eee",
   "metadata": {},
   "source": [
    "# Scaled Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c83d9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Life': 0, 'dessert': 1, 'eat': 2, 'is': 3, 'last': 4, 'short': 5}\n"
     ]
    }
   ],
   "source": [
    "input_sentence = 'Life is short, eat dessert last'\n",
    "input_sentence_list = input_sentence.replace(\",\", \"\").split()\n",
    "sentence_dict = {s : i for i, s in enumerate(sorted(input_sentence_list))}\n",
    "print(sentence_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59551016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 3, 5, 2, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "sentence_int = torch.tensor([sentence_dict[s] for s in input_sentence_list])\n",
    "print(sentence_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1cfd15",
   "metadata": {},
   "source": [
    "### Create the embedding\n",
    "We use a 16 dimensional embedding for each vector and since we have 6 words this means we get embeddings of shape 6x16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a954b52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "embed = torch.nn.Embedding(6, 16)\n",
    "embed_sentence = embed(sentence_int).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93420ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196, -0.3792,\n",
      "          0.7671, -1.1925,  0.6984, -1.4097,  0.1794,  1.8951,  0.4954,  0.2692],\n",
      "        [ 0.8768,  1.6221, -1.4779,  1.1331, -1.2203,  1.3139,  1.0533,  0.1388,\n",
      "          2.2473, -0.8036, -0.2808,  0.7697, -0.6596, -0.7979,  0.1838,  0.2293],\n",
      "        [ 0.2553, -0.5496,  1.0042,  0.8272, -0.3948,  0.4892, -0.2168, -1.7472,\n",
      "         -1.6025, -1.0764,  0.9031, -0.7218, -0.5951, -0.7112,  0.6230, -1.3729],\n",
      "        [-1.3250,  0.1784, -2.1338,  1.0524, -0.3885, -0.9343, -0.4991, -1.0867,\n",
      "          0.8805,  1.5542,  0.6266, -0.1755,  0.0983, -0.0935,  0.2662, -0.5850],\n",
      "        [-0.0770, -1.0205, -0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010,\n",
      "          0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255, -0.6315, -2.8400],\n",
      "        [ 0.5146,  0.9938, -0.2587, -1.0826, -0.0444,  1.6236, -2.3229,  1.0878,\n",
      "          0.6716,  0.6933, -0.9487, -0.0765, -0.1526,  0.1167,  0.4403, -1.4465]])\n",
      "torch.Size([6, 16])\n"
     ]
    }
   ],
   "source": [
    "print(embed_sentence)\n",
    "print(embed_sentence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7a53624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 16]) torch.Size([24, 16]) torch.Size([28, 16])\n"
     ]
    }
   ],
   "source": [
    "d = embed_sentence.shape[1]\n",
    "\n",
    "d_q, d_k, d_v = 24, 24, 28\n",
    "\n",
    "W_q = torch.randn(d_q, d)\n",
    "W_k = torch.randn(d_k, d)\n",
    "W_v = torch.randn(d_v, d)\n",
    "\n",
    "print(W_q.shape, W_k.shape, W_v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510bd7c0",
   "metadata": {},
   "source": [
    "## Step 1: Compute unnormalized attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8c1fed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8768,  1.6221, -1.4779,  1.1331, -1.2203,  1.3139,  1.0533,  0.1388,\n",
      "         2.2473, -0.8036, -0.2808,  0.7697, -0.6596, -0.7979,  0.1838,  0.2293])\n"
     ]
    }
   ],
   "source": [
    "x_2 = embed_sentence[1]\n",
    "print(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b62a333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24])\n",
      "torch.Size([24])\n",
      "torch.Size([28])\n"
     ]
    }
   ],
   "source": [
    "q_2 = W_q.matmul(x_2)\n",
    "k_2 = W_k.matmul(x_2)\n",
    "v_2 = W_v.matmul(x_2)\n",
    "\n",
    "print(q_2.shape)\n",
    "print(k_2.shape)\n",
    "print(v_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eca3a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 24]) torch.Size([6, 28])\n"
     ]
    }
   ],
   "source": [
    "keys = W_k.matmul(embed_sentence.T).T\n",
    "values = W_v.matmul(embed_sentence.T).T\n",
    "print(keys.shape, values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8dc8ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(58.9875)\n"
     ]
    }
   ],
   "source": [
    "omega_24 = q_2.dot(keys[4])\n",
    "print(omega_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c6fc0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -57.1016,  -85.4889,  160.1854, -144.2133,   58.9875,  -80.1705])\n"
     ]
    }
   ],
   "source": [
    "omega_2 = q_2.matmul(keys.T)\n",
    "print(omega_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebbdaaf",
   "metadata": {},
   "source": [
    "## Step 2: Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51895134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.4640e-20, 1.6633e-22, 1.0000e+00, 1.0353e-27, 1.0686e-09, 4.9255e-22])\n"
     ]
    }
   ],
   "source": [
    "attention_2 = torch.nn.functional.softmax(omega_2/(d_k**0.5), dim=0)\n",
    "print(attention_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eee934",
   "metadata": {},
   "source": [
    "## Step 3: Compute the Context Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9147b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.6812,  4.3038, -5.0492, -2.6208, -2.4619, -0.3670, -1.0982,  3.0041,\n",
      "        -2.2975,  3.9133, -3.7064, -1.8859,  3.9662, -4.3787, -1.7991,  4.1266,\n",
      "        -2.3905,  2.7373,  2.9809,  6.5839,  0.3691, -6.0942,  3.2605, -3.9929,\n",
      "         6.6571,  1.6524, -4.1800,  2.8630])\n",
      "torch.Size([28])\n"
     ]
    }
   ],
   "source": [
    "context_vector_2 = attention_2.matmul(values)\n",
    "print(context_vector_2)\n",
    "print(context_vector_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61da88f",
   "metadata": {},
   "source": [
    "# Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c81a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = embed_sentence[1]\n",
    "\n",
    "d = len(x_2)\n",
    "d_q, d_k, d_v = 24, 24, 28\n",
    "h = 3\n",
    "W_q = torch.randn(h, d_q, d)\n",
    "W_k = torch.randn(h, d_k, d)\n",
    "W_v = torch.randn(h, d_v, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "462d8394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 24, 16]) torch.Size([3, 24, 16]) torch.Size([3, 28, 16])\n"
     ]
    }
   ],
   "source": [
    "print(W_q.shape, W_k.shape, W_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adfce46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 24])\n"
     ]
    }
   ],
   "source": [
    "q_2 = W_q.matmul(x_2)\n",
    "print(q_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4452af0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 6])\n"
     ]
    }
   ],
   "source": [
    "# Stack the inputs for multi head\n",
    "input_stack = embed_sentence.T.repeat(3, 1, 1)\n",
    "print(input_stack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10128987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 24, 6]) torch.Size([3, 28, 6])\n"
     ]
    }
   ],
   "source": [
    "keys = torch.bmm(W_k, input_stack)\n",
    "values = torch.bmm(W_v, input_stack)\n",
    "print(keys.shape, values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af22f25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 24])\n"
     ]
    }
   ],
   "source": [
    "q_2 = q_2.unsqueeze(-1).swapaxes(-1, -2)\n",
    "print(q_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df660954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "omega_2 = torch.bmm(q_2, keys).squeeze()\n",
    "print(omega_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f917dfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Normalize the dot product\n",
    "attention_2 = torch.nn.functional.softmax(omega_2/(d_k**0.5), dim=1)\n",
    "print(attention_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78c3157d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28])\n"
     ]
    }
   ],
   "source": [
    "# Compute the context vector\n",
    "context_vector_2 = torch.bmm(values, attention_2.unsqueeze(-1)).squeeze()\n",
    "print(context_vector_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33167f3d",
   "metadata": {},
   "source": [
    "### References\n",
    "1. [Understanding and Coding the Self-Attention Mechanism of Large Language Models From Scratch](https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html) by Sebastian Raschka, PhD.\n",
    "\n",
    "2. [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf) by Vaswani Et.al"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
